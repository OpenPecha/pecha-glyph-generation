{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af76465-a773-4008-b40c-416529fecd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "IMAGE_SIZE = 128\n",
    "BATCH_SIZE = 16\n",
    "BUFFER_SIZE = 1000\n",
    "\n",
    "def load_image(image_path, image_size=IMAGE_SIZE):\n",
    "    \"\"\"Load an image from the disk, resize and normalize.\"\"\"\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_png(image, channels=1)  # Decoding PNG (for glyphs)\n",
    "    image = tf.image.resize(image, [image_size, image_size])\n",
    "    image = (image / 127.5) - 1.0  # Normalize to [-1, 1]\n",
    "    return image\n",
    "\n",
    "def load_image_pair(conditonal_path, derge_path):\n",
    "    \"\"\"Load and return a pair of conditonal and Derge images.\"\"\"\n",
    "    conditonal_image = load_image(conditonal_path)\n",
    "    derge_image = load_image(derge_path)\n",
    "    return conditonal_image, derge_image\n",
    "\n",
    "def prepare_dataset(conditonal_dir, derge_dir):\n",
    "    \"\"\"Create TensorFlow dataset with paired images from both directories.\"\"\"\n",
    "    # Get list of image file names\n",
    "    conditonal_image_paths = sorted([os.path.join(conditonal_dir, fname) for fname in os.listdir(conditonal_dir)])\n",
    "    derge_image_paths = sorted([os.path.join(derge_dir, fname) for fname in os.listdir(derge_dir)])\n",
    "    \n",
    "    # Create a dataset from the file paths\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((conditonal_image_paths, derge_image_paths))\n",
    "    \n",
    "    # Load images in parallel, shuffle, and batch them\n",
    "    dataset = dataset.map(lambda x, y: load_image_pair(x, y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "# Paths to the directories containing conditonal and Derge glyphs\n",
    "conditonal_dir = \"../data/condition_images\"\n",
    "derge_dir = \"../data/derge_glyph_images\"\n",
    "\n",
    "# Prepare the dataset\n",
    "dataset = prepare_dataset(conditonal_dir, derge_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96797a05-6026-42d8-8474-48c2405eb6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def build_generator():\n",
    "    \"\"\"Builds the generator model to map a Monlam glyph image to a Derge glyph image.\"\"\"\n",
    "    \n",
    "    # Input: Monlam glyph image\n",
    "    inputs = layers.Input(shape=(128, 128, 1))\n",
    "    \n",
    "    # Encoder\n",
    "    down1 = layers.Conv2D(64, (4, 4), strides=2, padding='same')(inputs)\n",
    "    down1 = layers.LeakyReLU()(down1)\n",
    "    \n",
    "    down2 = layers.Conv2D(128, (4, 4), strides=2, padding='same')(down1)\n",
    "    down2 = layers.BatchNormalization()(down2)\n",
    "    down2 = layers.LeakyReLU()(down2)\n",
    "    \n",
    "    down3 = layers.Conv2D(256, (4, 4), strides=2, padding='same')(down2)\n",
    "    down3 = layers.BatchNormalization()(down3)\n",
    "    down3 = layers.LeakyReLU()(down3)\n",
    "    \n",
    "    down4 = layers.Conv2D(512, (4, 4), strides=2, padding='same')(down3)\n",
    "    down4 = layers.BatchNormalization()(down4)\n",
    "    down4 = layers.LeakyReLU()(down4)\n",
    "    \n",
    "    # Bottleneck\n",
    "    bottleneck = layers.Conv2D(512, (4, 4), strides=2, padding='same')(down4)\n",
    "    bottleneck = layers.ReLU()(bottleneck)\n",
    "    \n",
    "    # Decoder (Upsampling)\n",
    "    up1 = layers.Conv2DTranspose(512, (4, 4), strides=2, padding='same')(bottleneck)\n",
    "    up1 = layers.BatchNormalization()(up1)\n",
    "    up1 = layers.ReLU()(up1)\n",
    "    up1 = layers.Concatenate()([up1, down4])\n",
    "    \n",
    "    up2 = layers.Conv2DTranspose(256, (4, 4), strides=2, padding='same')(up1)\n",
    "    up2 = layers.BatchNormalization()(up2)\n",
    "    up2 = layers.ReLU()(up2)\n",
    "    up2 = layers.Concatenate()([up2, down3])\n",
    "    \n",
    "    up3 = layers.Conv2DTranspose(128, (4, 4), strides=2, padding='same')(up2)\n",
    "    up3 = layers.BatchNormalization()(up3)\n",
    "    up3 = layers.ReLU()(up3)\n",
    "    up3 = layers.Concatenate()([up3, down2])\n",
    "    \n",
    "    up4 = layers.Conv2DTranspose(64, (4, 4), strides=2, padding='same')(up3)\n",
    "    up4 = layers.BatchNormalization()(up4)\n",
    "    up4 = layers.ReLU()(up4)\n",
    "    up4 = layers.Concatenate()([up4, down1])\n",
    "    \n",
    "    # Output layer (Derge glyph image)\n",
    "    outputs = layers.Conv2DTranspose(1, (4, 4), strides=2, padding='same', activation='tanh')(up4)\n",
    "    \n",
    "    return tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# Build the generator\n",
    "generator = build_generator()\n",
    "generator.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aad03d8-2405-4444-8f00-a0b53d4a0d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "    \"\"\"Builds the discriminator model to classify real vs fake Derge glyph images.\"\"\"\n",
    "    \n",
    "    # Input: Monlam glyph image\n",
    "    monlam_input = layers.Input(shape=(128, 128, 1))\n",
    "    \n",
    "    # Input: Derge glyph image (either real or generated)\n",
    "    derge_input = layers.Input(shape=(128, 128, 1))\n",
    "    \n",
    "    # Combine the condition (Monlam) and the target (Derge) glyph images\n",
    "    combined_input = layers.Concatenate()([monlam_input, derge_input])\n",
    "    \n",
    "    # Discriminator network (PatchGAN)\n",
    "    down1 = layers.Conv2D(64, (4, 4), strides=2, padding='same')(combined_input)\n",
    "    down1 = layers.LeakyReLU()(down1)\n",
    "    \n",
    "    down2 = layers.Conv2D(128, (4, 4), strides=2, padding='same')(down1)\n",
    "    down2 = layers.BatchNormalization()(down2)\n",
    "    down2 = layers.LeakyReLU()(down2)\n",
    "    \n",
    "    down3 = layers.Conv2D(256, (4, 4), strides=2, padding='same')(down2)\n",
    "    down3 = layers.BatchNormalization()(down3)\n",
    "    down3 = layers.LeakyReLU()(down3)\n",
    "    \n",
    "    down4 = layers.Conv2D(512, (4, 4), strides=2, padding='same')(down3)\n",
    "    down4 = layers.BatchNormalization()(down4)\n",
    "    down4 = layers.LeakyReLU()(down4)\n",
    "    \n",
    "    # Output layer (real/fake classification)\n",
    "    outputs = layers.Conv2D(1, (4, 4), strides=1, padding='same')(down4)\n",
    "    \n",
    "    return tf.keras.Model([monlam_input, derge_input], outputs)\n",
    "\n",
    "# Build the discriminator\n",
    "discriminator = build_discriminator()\n",
    "discriminator.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38842db-b774-4880-beac-f665ad2457c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Compile the cGAN model using the generator and discriminator\n",
    "def compile_cgan(generator, discriminator, lambda_l1=100):\n",
    "    # Loss functions\n",
    "    binary_cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "    \n",
    "    def generator_loss(disc_generated_output, gen_output, target):\n",
    "        adv_loss = binary_cross_entropy(tf.ones_like(disc_generated_output), disc_generated_output)\n",
    "        l1_loss = tf.reduce_mean(tf.abs(target - gen_output))\n",
    "        total_gen_loss = adv_loss + (lambda_l1 * l1_loss)\n",
    "        return total_gen_loss\n",
    "    \n",
    "    def discriminator_loss(disc_real_output, disc_generated_output):\n",
    "        real_loss = binary_cross_entropy(tf.ones_like(disc_real_output), disc_real_output)\n",
    "        fake_loss = binary_cross_entropy(tf.zeros_like(disc_generated_output), disc_generated_output)\n",
    "        total_disc_loss = (real_loss + fake_loss) / 2\n",
    "        return total_disc_loss\n",
    "    \n",
    "    # Optimizers\n",
    "    generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "    discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "    \n",
    "    # Compile the models\n",
    "    generator.compile(optimizer=generator_optimizer, loss=generator_loss)\n",
    "    discriminator.compile(optimizer=discriminator_optimizer, loss=discriminator_loss)\n",
    "\n",
    "# Initialize and compile the model\n",
    "generator = build_generator()\n",
    "discriminator = build_discriminator()\n",
    "compile_cgan(generator, discriminator)\n",
    "\n",
    "# Callback for saving model weights during training\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix, save_weights_only=True)\n",
    "\n",
    "# Function to train the model using tf.keras.Model.fit()\n",
    "def train_cgan(generator, discriminator, dataset, epochs=100):\n",
    "    for epoch in range(epochs):\n",
    "        print(f'Starting epoch {epoch+1}/{epochs}')\n",
    "        \n",
    "        for step, (monlam_images, derge_images) in enumerate(dataset):\n",
    "            # Train the generator and discriminator\n",
    "            generated_images = generator(monlam_images, training=True)\n",
    "            \n",
    "            # Real and fake outputs for discriminator\n",
    "            real_output = discriminator([monlam_images, derge_images], training=True)\n",
    "            fake_output = discriminator([monlam_images, generated_images], training=True)\n",
    "            \n",
    "            # Compute losses\n",
    "            gen_loss = generator_loss(fake_output, generated_images, derge_images)\n",
    "            disc_loss = discriminator_loss(real_output, fake_output)\n",
    "            \n",
    "            # Print progress\n",
    "            if step % 100 == 0:\n",
    "                print(f'Step {step}, Gen Loss: {gen_loss.numpy()}, Disc Loss: {disc_loss.numpy()}')\n",
    "\n",
    "# Training the cGAN\n",
    "train_cgan(generator, discriminator, dataset, epochs=10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
