{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af76465-a773-4008-b40c-416529fecd9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-18 08:20:37.715935: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-18 08:20:37.736812: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-18 08:20:37.743203: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-18 08:20:37.759385: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-18 08:20:40.501077: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10394 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:0c:00.0, compute capability: 8.6\n",
      "2024-09-18 08:20:40.501980: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 10394 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:0d:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset - Conditional Image Batch Shape: (16, 128, 128, 1)\n",
      "Train Dataset - Derge Image Batch Shape: (16, 128, 128, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-18 08:20:41.112049: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Dataset - Conditional Image Batch Shape: (16, 128, 128, 1)\n",
      "Validation Dataset - Derge Image Batch Shape: (16, 128, 128, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-18 08:20:42.032764: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Dataset - Conditional Image Batch Shape: (16, 128, 128, 1)\n",
      "Test Dataset - Derge Image Batch Shape: (16, 128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# Constants\n",
    "IMAGE_SIZE = 128\n",
    "BATCH_SIZE = 16\n",
    "BUFFER_SIZE = 1000\n",
    "SPLIT_RATIO = {\"train\": 0.8, \"val\": 0.1, \"test\": 0.1}\n",
    "\n",
    "# Load and augment images\n",
    "def load_image(image_path, image_size=IMAGE_SIZE):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_png(image, channels=1)\n",
    "    image = tf.image.resize(image, [image_size, image_size])\n",
    "    image = (image / 127.5) - 1.0\n",
    "    return image\n",
    "\n",
    "def augment_image(image):\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    image = tf.image.random_brightness(image, max_delta=0.2)\n",
    "    image = tf.image.random_contrast(image, lower=0.8, upper=1.2)\n",
    "    return image\n",
    "\n",
    "def load_image_pair(conditonal_path, derge_path, augment=False):\n",
    "    conditonal_image = load_image(conditonal_path)\n",
    "    derge_image = load_image(derge_path)\n",
    "    if augment:\n",
    "        conditonal_image = augment_image(conditonal_image)\n",
    "        derge_image = augment_image(derge_image)\n",
    "    return conditonal_image, derge_image\n",
    "\n",
    "def prepare_dataset(conditonal_dir, derge_dir, augment=False):\n",
    "    conditonal_image_paths = sorted([os.path.join(conditonal_dir, fname) for fname in os.listdir(conditonal_dir)])\n",
    "    derge_image_paths = sorted([os.path.join(derge_dir, fname) for fname in os.listdir(derge_dir)])\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((conditonal_image_paths, derge_image_paths))\n",
    "    dataset = dataset.map(lambda x, y: load_image_pair(x, y, augment), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    \n",
    "    dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    total_size = len(conditonal_image_paths)\n",
    "    train_size = int(SPLIT_RATIO[\"train\"] * total_size)\n",
    "    val_size = int(SPLIT_RATIO[\"val\"] * total_size)\n",
    "    \n",
    "    train_dataset = dataset.take(train_size // BATCH_SIZE)\n",
    "    remaining_dataset = dataset.skip(train_size // BATCH_SIZE)\n",
    "    \n",
    "    val_dataset = remaining_dataset.take(val_size // BATCH_SIZE)\n",
    "    test_dataset = remaining_dataset.skip(val_size // BATCH_SIZE)\n",
    "    \n",
    "    return train_dataset, val_dataset, test_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96797a05-6026-42d8-8474-48c2405eb6b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,088</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,200</span> │ leaky_re_lu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">524,544</span> │ leaky_re_lu_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,097,664</span> │ leaky_re_lu_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">4,194,816</span> │ leaky_re_lu_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_transpose    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">4,194,816</span> │ re_lu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)   │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_transpose… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>,      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │ leaky_re_lu_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_transpose_1  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │  <span style=\"color: #00af00; text-decoration-color: #00af00\">4,194,560</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_transpose… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │ leaky_re_lu_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_transpose_2  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,048,704</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_transpose… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │ leaky_re_lu_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_transpose_3  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,208</span> │ concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_transpose… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │ leaky_re_lu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_transpose_4  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,049</span> │ concatenate_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m1\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │      \u001b[38;5;34m1,088\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │    \u001b[38;5;34m131,200\u001b[0m │ leaky_re_lu[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │    \u001b[38;5;34m524,544\u001b[0m │ leaky_re_lu_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) │  \u001b[38;5;34m2,097,664\u001b[0m │ leaky_re_lu_2[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) │      \u001b[38;5;34m2,048\u001b[0m │ conv2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_3       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m) │  \u001b[38;5;34m4,194,816\u001b[0m │ leaky_re_lu_3[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu (\u001b[38;5;33mReLU\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ conv2d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_transpose    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) │  \u001b[38;5;34m4,194,816\u001b[0m │ re_lu[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)   │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) │      \u001b[38;5;34m2,048\u001b[0m │ conv2d_transpose… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_1 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m,      │          \u001b[38;5;34m0\u001b[0m │ re_lu_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m1024\u001b[0m)             │            │ leaky_re_lu_3[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_transpose_1  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │  \u001b[38;5;34m4,194,560\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)   │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv2d_transpose… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_2 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ re_lu_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m512\u001b[0m)              │            │ leaky_re_lu_2[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_transpose_2  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │  \u001b[38;5;34m1,048,704\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)   │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_transpose… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_3 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ re_lu_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m256\u001b[0m)              │            │ leaky_re_lu_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_transpose_3  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │    \u001b[38;5;34m262,208\u001b[0m │ concatenate_2[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)   │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2d_transpose… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_4 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_3       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ re_lu_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m128\u001b[0m)              │            │ leaky_re_lu[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_transpose_4  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │      \u001b[38;5;34m2,049\u001b[0m │ concatenate_3[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)   │ \u001b[38;5;34m1\u001b[0m)                │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,659,073</span> (63.55 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m16,659,073\u001b[0m (63.55 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,655,361</span> (63.54 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m16,655,361\u001b[0m (63.54 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,712</span> (14.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m3,712\u001b[0m (14.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def build_generator():\n",
    "    \"\"\"Builds the generator model to map a Monlam glyph image to a Derge glyph image.\"\"\"\n",
    "    \n",
    "    # Input: Monlam glyph image\n",
    "    inputs = layers.Input(shape=(128, 128, 1))\n",
    "    \n",
    "    # Encoder\n",
    "    down1 = layers.Conv2D(64, (4, 4), strides=2, padding='same')(inputs)\n",
    "    down1 = layers.LeakyReLU()(down1)\n",
    "    \n",
    "    down2 = layers.Conv2D(128, (4, 4), strides=2, padding='same')(down1)\n",
    "    down2 = layers.BatchNormalization()(down2)\n",
    "    down2 = layers.LeakyReLU()(down2)\n",
    "    \n",
    "    down3 = layers.Conv2D(256, (4, 4), strides=2, padding='same')(down2)\n",
    "    down3 = layers.BatchNormalization()(down3)\n",
    "    down3 = layers.LeakyReLU()(down3)\n",
    "    \n",
    "    down4 = layers.Conv2D(512, (4, 4), strides=2, padding='same')(down3)\n",
    "    down4 = layers.BatchNormalization()(down4)\n",
    "    down4 = layers.LeakyReLU()(down4)\n",
    "    \n",
    "    # Bottleneck\n",
    "    bottleneck = layers.Conv2D(512, (4, 4), strides=2, padding='same')(down4)\n",
    "    bottleneck = layers.ReLU()(bottleneck)\n",
    "    \n",
    "    # Decoder (Upsampling)\n",
    "    up1 = layers.Conv2DTranspose(512, (4, 4), strides=2, padding='same')(bottleneck)\n",
    "    up1 = layers.BatchNormalization()(up1)\n",
    "    up1 = layers.ReLU()(up1)\n",
    "    up1 = layers.Concatenate()([up1, down4])\n",
    "    \n",
    "    up2 = layers.Conv2DTranspose(256, (4, 4), strides=2, padding='same')(up1)\n",
    "    up2 = layers.BatchNormalization()(up2)\n",
    "    up2 = layers.ReLU()(up2)\n",
    "    up2 = layers.Concatenate()([up2, down3])\n",
    "    \n",
    "    up3 = layers.Conv2DTranspose(128, (4, 4), strides=2, padding='same')(up2)\n",
    "    up3 = layers.BatchNormalization()(up3)\n",
    "    up3 = layers.ReLU()(up3)\n",
    "    up3 = layers.Concatenate()([up3, down2])\n",
    "    \n",
    "    up4 = layers.Conv2DTranspose(64, (4, 4), strides=2, padding='same')(up3)\n",
    "    up4 = layers.BatchNormalization()(up4)\n",
    "    up4 = layers.ReLU()(up4)\n",
    "    up4 = layers.Concatenate()([up4, down1])\n",
    "    \n",
    "    # Output layer (Derge glyph image)\n",
    "    outputs = layers.Conv2DTranspose(1, (4, 4), strides=2, padding='same', activation='tanh')(up4)\n",
    "    \n",
    "    return tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# Build the generator\n",
    "generator = build_generator()\n",
    "generator.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7aad03d8-2405-4444-8f00-a0b53d4a0d99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_4       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                │            │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │ concatenate_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_4       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,200</span> │ leaky_re_lu_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_5       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">524,544</span> │ leaky_re_lu_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_6       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,097,664</span> │ leaky_re_lu_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_7       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,193</span> │ leaky_re_lu_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m1\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m1\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_4       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m2\u001b[0m)                │            │ input_layer_2[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │      \u001b[38;5;34m2,112\u001b[0m │ concatenate_4[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_4       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │    \u001b[38;5;34m131,200\u001b[0m │ leaky_re_lu_4[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_5       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │    \u001b[38;5;34m524,544\u001b[0m │ leaky_re_lu_5[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv2d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_6       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) │  \u001b[38;5;34m2,097,664\u001b[0m │ leaky_re_lu_6[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) │      \u001b[38;5;34m2,048\u001b[0m │ conv2d_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_7       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)   │      \u001b[38;5;34m8,193\u001b[0m │ leaky_re_lu_7[\u001b[38;5;34m0\u001b[0m]… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,767,297</span> (10.56 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,767,297\u001b[0m (10.56 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,765,505</span> (10.55 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,765,505\u001b[0m (10.55 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> (7.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,792\u001b[0m (7.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def build_discriminator():\n",
    "    \"\"\"Builds the discriminator model to classify real vs fake Derge glyph images.\"\"\"\n",
    "    \n",
    "    # Input: Monlam glyph image\n",
    "    monlam_input = layers.Input(shape=(128, 128, 1))\n",
    "    \n",
    "    # Input: Derge glyph image (either real or generated)\n",
    "    derge_input = layers.Input(shape=(128, 128, 1))\n",
    "    \n",
    "    # Combine the condition (Monlam) and the target (Derge) glyph images\n",
    "    combined_input = layers.Concatenate()([monlam_input, derge_input])\n",
    "    \n",
    "    # Discriminator network (PatchGAN)\n",
    "    down1 = layers.Conv2D(64, (4, 4), strides=2, padding='same')(combined_input)\n",
    "    down1 = layers.LeakyReLU()(down1)\n",
    "    \n",
    "    down2 = layers.Conv2D(128, (4, 4), strides=2, padding='same')(down1)\n",
    "    down2 = layers.BatchNormalization()(down2)\n",
    "    down2 = layers.LeakyReLU()(down2)\n",
    "    \n",
    "    down3 = layers.Conv2D(256, (4, 4), strides=2, padding='same')(down2)\n",
    "    down3 = layers.BatchNormalization()(down3)\n",
    "    down3 = layers.LeakyReLU()(down3)\n",
    "    \n",
    "    down4 = layers.Conv2D(512, (4, 4), strides=2, padding='same')(down3)\n",
    "    down4 = layers.BatchNormalization()(down4)\n",
    "    down4 = layers.LeakyReLU()(down4)\n",
    "    \n",
    "    # Output layer (real/fake classification)\n",
    "    outputs = layers.Conv2D(1, (4, 4), strides=1, padding='same')(down4)\n",
    "    \n",
    "    return tf.keras.Model([monlam_input, derge_input], outputs)\n",
    "\n",
    "# Build the discriminator\n",
    "discriminator = build_discriminator()\n",
    "discriminator.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a38842db-b774-4880-beac-f665ad2457c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models have been compiled successfully.\n",
      "Generator model summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,088</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_8       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,200</span> │ leaky_re_lu_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_9       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">524,544</span> │ leaky_re_lu_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_10      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,097,664</span> │ leaky_re_lu_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_11      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">4,194,816</span> │ leaky_re_lu_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_transpose_5  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">4,194,816</span> │ re_lu_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)   │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_transpose… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_5       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>,      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │ leaky_re_lu_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_transpose_6  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │  <span style=\"color: #00af00; text-decoration-color: #00af00\">4,194,560</span> │ concatenate_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_transpose… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_6       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │ leaky_re_lu_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_transpose_7  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,048,704</span> │ concatenate_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_transpose… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_7       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │ leaky_re_lu_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_transpose_8  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,208</span> │ concatenate_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_transpose… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_8       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │ leaky_re_lu_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_transpose_9  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,049</span> │ concatenate_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m1\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │      \u001b[38;5;34m1,088\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_8       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │    \u001b[38;5;34m131,200\u001b[0m │ leaky_re_lu_8[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_9       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_12 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │    \u001b[38;5;34m524,544\u001b[0m │ leaky_re_lu_9[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv2d_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_10      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_13 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) │  \u001b[38;5;34m2,097,664\u001b[0m │ leaky_re_lu_10[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) │      \u001b[38;5;34m2,048\u001b[0m │ conv2d_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_11      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_14 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m) │  \u001b[38;5;34m4,194,816\u001b[0m │ leaky_re_lu_11[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_5 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ conv2d_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_transpose_5  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) │  \u001b[38;5;34m4,194,816\u001b[0m │ re_lu_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)   │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) │      \u001b[38;5;34m2,048\u001b[0m │ conv2d_transpose… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_6 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_5       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m,      │          \u001b[38;5;34m0\u001b[0m │ re_lu_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m1024\u001b[0m)             │            │ leaky_re_lu_11[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_transpose_6  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │  \u001b[38;5;34m4,194,560\u001b[0m │ concatenate_5[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)   │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv2d_transpose… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_7 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_6       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ re_lu_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m512\u001b[0m)              │            │ leaky_re_lu_10[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_transpose_7  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │  \u001b[38;5;34m1,048,704\u001b[0m │ concatenate_6[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)   │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_transpose… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_8 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_7       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ re_lu_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m256\u001b[0m)              │            │ leaky_re_lu_9[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_transpose_8  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │    \u001b[38;5;34m262,208\u001b[0m │ concatenate_7[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)   │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2d_transpose… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_9 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_8       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ re_lu_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m128\u001b[0m)              │            │ leaky_re_lu_8[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_transpose_9  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │      \u001b[38;5;34m2,049\u001b[0m │ concatenate_8[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)   │ \u001b[38;5;34m1\u001b[0m)                │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,659,073</span> (63.55 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m16,659,073\u001b[0m (63.55 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,655,361</span> (63.54 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m16,655,361\u001b[0m (63.54 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,712</span> (14.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m3,712\u001b[0m (14.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator model summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_5       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_9       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                │            │ input_layer_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │ concatenate_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_12      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,200</span> │ leaky_re_lu_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_13      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">524,544</span> │ leaky_re_lu_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_14      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,097,664</span> │ leaky_re_lu_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_15      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,193</span> │ leaky_re_lu_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m1\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_5       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m1\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_9       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ input_layer_4[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m2\u001b[0m)                │            │ input_layer_5[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_15 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │      \u001b[38;5;34m2,112\u001b[0m │ concatenate_9[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_12      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_16 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │    \u001b[38;5;34m131,200\u001b[0m │ leaky_re_lu_12[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_13      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_17 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │    \u001b[38;5;34m524,544\u001b[0m │ leaky_re_lu_13[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv2d_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_14      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_18 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) │  \u001b[38;5;34m2,097,664\u001b[0m │ leaky_re_lu_14[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) │      \u001b[38;5;34m2,048\u001b[0m │ conv2d_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_15      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_19 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)   │      \u001b[38;5;34m8,193\u001b[0m │ leaky_re_lu_15[\u001b[38;5;34m0\u001b[0m… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,767,297</span> (10.56 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,767,297\u001b[0m (10.56 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,765,505</span> (10.55 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,765,505\u001b[0m (10.55 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> (7.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,792\u001b[0m (7.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint callback has been created. Checkpoints will be saved to: ./training_checkpoints/ckpt.weights.h5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "def compile_cgan(generator, discriminator, lambda_l1=100):\n",
    "    binary_cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "    \n",
    "    def generator_loss(disc_generated_output, gen_output, target):\n",
    "        adv_loss = binary_cross_entropy(tf.ones_like(disc_generated_output), disc_generated_output)\n",
    "        l1_loss = tf.reduce_mean(tf.abs(target - gen_output))\n",
    "        total_gen_loss = adv_loss + (lambda_l1 * l1_loss)\n",
    "        return total_gen_loss\n",
    "    \n",
    "    def discriminator_loss(disc_real_output, disc_generated_output):\n",
    "        real_loss = binary_cross_entropy(tf.ones_like(disc_real_output), disc_real_output)\n",
    "        fake_loss = binary_cross_entropy(tf.zeros_like(disc_generated_output), disc_generated_output)\n",
    "        total_disc_loss = (real_loss + fake_loss) / 2\n",
    "        return total_disc_loss\n",
    "    \n",
    "    generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "    discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "    \n",
    "    # Compile the models\n",
    "    generator.compile(optimizer=generator_optimizer, loss=generator_loss)\n",
    "    discriminator.compile(optimizer=discriminator_optimizer, loss=discriminator_loss)\n",
    "    \n",
    "    print(\"Models have been compiled successfully.\")\n",
    "    print(\"Generator model summary:\")\n",
    "    generator.summary()\n",
    "    print(\"Discriminator model summary:\")\n",
    "    discriminator.summary()\n",
    "\n",
    "# Initialize and compile the models\n",
    "generator = build_generator()\n",
    "discriminator = build_discriminator()\n",
    "compile_cgan(generator, discriminator)\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt.weights.h5\")\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix, save_weights_only=True)\n",
    "\n",
    "print(f\"Checkpoint callback has been created. Checkpoints will be saved to: {checkpoint_prefix}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "211c22f5-f446-4faa-a920-a218296cb42f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models have been compiled successfully.\n",
      "Generator model summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_6       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,088</span> │ input_layer_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_16      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,200</span> │ leaky_re_lu_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_17      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">524,544</span> │ leaky_re_lu_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_18      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,097,664</span> │ leaky_re_lu_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_19      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">4,194,816</span> │ leaky_re_lu_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_transpose_10 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">4,194,816</span> │ re_lu_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)   │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_transpose… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_10      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>,      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │ leaky_re_lu_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_transpose_11 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │  <span style=\"color: #00af00; text-decoration-color: #00af00\">4,194,560</span> │ concatenate_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_transpose… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_11      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │ leaky_re_lu_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_transpose_12 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,048,704</span> │ concatenate_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_transpose… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_12      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │ leaky_re_lu_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_transpose_13 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,208</span> │ concatenate_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_transpose… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_13      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │ leaky_re_lu_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_transpose_14 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,049</span> │ concatenate_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_6       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m1\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_20 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │      \u001b[38;5;34m1,088\u001b[0m │ input_layer_6[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_16      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_21 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │    \u001b[38;5;34m131,200\u001b[0m │ leaky_re_lu_16[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_17      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_22 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │    \u001b[38;5;34m524,544\u001b[0m │ leaky_re_lu_17[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv2d_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_18      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_23 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) │  \u001b[38;5;34m2,097,664\u001b[0m │ leaky_re_lu_18[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) │      \u001b[38;5;34m2,048\u001b[0m │ conv2d_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_19      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_24 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m) │  \u001b[38;5;34m4,194,816\u001b[0m │ leaky_re_lu_19[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_10 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ conv2d_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_transpose_10 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) │  \u001b[38;5;34m4,194,816\u001b[0m │ re_lu_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)   │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) │      \u001b[38;5;34m2,048\u001b[0m │ conv2d_transpose… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_11 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_10      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m,      │          \u001b[38;5;34m0\u001b[0m │ re_lu_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m1024\u001b[0m)             │            │ leaky_re_lu_19[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_transpose_11 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │  \u001b[38;5;34m4,194,560\u001b[0m │ concatenate_10[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)   │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv2d_transpose… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_12 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_11      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ re_lu_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m512\u001b[0m)              │            │ leaky_re_lu_18[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_transpose_12 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │  \u001b[38;5;34m1,048,704\u001b[0m │ concatenate_11[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)   │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_transpose… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_13 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_12      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ re_lu_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m256\u001b[0m)              │            │ leaky_re_lu_17[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_transpose_13 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │    \u001b[38;5;34m262,208\u001b[0m │ concatenate_12[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)   │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2d_transpose… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_14 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_13      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ re_lu_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m128\u001b[0m)              │            │ leaky_re_lu_16[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_transpose_14 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │      \u001b[38;5;34m2,049\u001b[0m │ concatenate_13[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)   │ \u001b[38;5;34m1\u001b[0m)                │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,659,073</span> (63.55 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m16,659,073\u001b[0m (63.55 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,655,361</span> (63.54 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m16,655,361\u001b[0m (63.54 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,712</span> (14.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m3,712\u001b[0m (14.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator model summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_7       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_8       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_14      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                │            │ input_layer_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │ concatenate_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_20      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,200</span> │ leaky_re_lu_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_21      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">524,544</span> │ leaky_re_lu_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_22      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,097,664</span> │ leaky_re_lu_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_28[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_23      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,193</span> │ leaky_re_lu_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_7       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m1\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_8       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m1\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_14      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ input_layer_7[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m2\u001b[0m)                │            │ input_layer_8[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_25 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │      \u001b[38;5;34m2,112\u001b[0m │ concatenate_14[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_20      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_26 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │    \u001b[38;5;34m131,200\u001b[0m │ leaky_re_lu_20[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_21      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_27 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │    \u001b[38;5;34m524,544\u001b[0m │ leaky_re_lu_21[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv2d_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_22      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_28 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) │  \u001b[38;5;34m2,097,664\u001b[0m │ leaky_re_lu_22[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) │      \u001b[38;5;34m2,048\u001b[0m │ conv2d_28[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_23      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_29 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)   │      \u001b[38;5;34m8,193\u001b[0m │ leaky_re_lu_23[\u001b[38;5;34m0\u001b[0m… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,767,297</span> (10.56 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,767,297\u001b[0m (10.56 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,765,505</span> (10.55 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,765,505\u001b[0m (10.55 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> (7.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,792\u001b[0m (7.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-18 08:22:09.066024: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8906\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1726647729.188081   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647729.224603   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647729.238853   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647729.239825   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647729.242688   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647729.245155   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647729.247424   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647729.248422   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647729.249377   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647729.250484   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647729.253463   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647729.254508   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647729.255773   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647729.257040   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647729.258311   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647729.259517   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647729.262716   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647729.266109   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647729.269492   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647729.271257   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647729.274761   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647729.276254   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647729.279655   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647729.281483   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647729.300498   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647729.303893   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647729.307572   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647729.309947   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647729.313721   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647729.371624   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647729.378613   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647729.379939   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647729.381253   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647729.382554   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647729.383847   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647729.385141   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647729.386500   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647729.387851   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647729.389241   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647729.390623   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647729.393551   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647729.395005   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647729.396441   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647729.397812   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647729.399190   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647729.400534   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647729.401900   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647729.403313   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647729.406825   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647729.408195   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647729.409679   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647729.411156   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647729.412674   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647729.416232   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647729.417726   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647729.419234   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647729.420967   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647729.422690   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647729.424389   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647729.426173   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647729.428013   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647729.429909   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647729.432000   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.042915   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.044189   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.045433   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.046745   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.048060   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.049360   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.050583   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.051898   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.053256   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.054519   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.055818   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.057176   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.058494   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.059985   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.061274   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.062774   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.064043   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.065327   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.066570   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.067905   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.069147   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.070480   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.071764   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.073192   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.074564   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.075922   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.077301   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.078702   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.080492   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.082193   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.084048   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.085729   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.087548   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.089476   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.123728   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.125045   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.126363   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.127716   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.128976   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.130296   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.131608   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.132839   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.134311   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.135572   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.136818   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.138084   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.139421   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.140864   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.142312   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.143774   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.145117   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.146495   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.147956   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.149314   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.150737   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.152108   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.153483   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.154928   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.156293   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.157715   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.159174   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.160852   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.162340   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.164366   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.166501   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.168419   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.170441   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.173435   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.175504   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.210190   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.211461   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.212666   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.213901   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.215101   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.216307   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.217791   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.218976   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.220460   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.221948   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.223131   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.224630   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.226077   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.227492   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.228636   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.229797   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.230893   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.232107   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.233271   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.234539   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.235812   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.237097   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.239063   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.240255   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.241353   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.242675   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.244657   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.245804   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.246930   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.248047   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.249513   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.251119   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.253095   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.374448   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.375551   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.428218   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.430555   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.432009   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.433433   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.434879   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.435984   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.440154   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.441314   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.442912   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.445875   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.447496   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.449109   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.450256   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.453347   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.458003   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.461665   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.462808   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.464118   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.466082   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.499230   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.500888   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.502625   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.504232   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.505950   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.508826   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.511435   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.514169   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.516743   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.518518   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.521391   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.523971   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.527580   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.530458   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.532599   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.534587   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.538762   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.541193   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.544847   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.547209   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.551852   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.577937   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.579531   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.581082   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.582644   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.584336   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.585934   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.588169   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.590623   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.593048   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.594963   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.597426   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.599892   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.602446   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.604914   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.607389   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.610994   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.614578   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.616726   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.619074   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.621479   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.623857   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.647474   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.649108   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.650772   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.653047   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.655026   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.657313   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.659841   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.662354   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.664797   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.667323   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.669789   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.673354   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.675888   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.678372   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.680963   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.683389   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.689454   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.695542   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.697827   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.700537   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.703280   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.724642   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.725770   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.726881   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.728828   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.730603   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.732377   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.734183   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.736023   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.738714   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.741586   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.744071   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.746560   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.757796   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.761090   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.765064   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.769077   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.780694   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.788747   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.815438   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.816879   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.842070   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.842916   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.843748   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.844577   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.845420   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.846252   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.847084   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.847957   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.848812   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.849869   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.850978   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.851904   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.853059   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.854203   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.855371   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.856453   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.857930   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.859172   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.860408   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.861622   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.863113   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.864403   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.865687   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.866977   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.868603   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.869694   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.871226   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.872871   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.874408   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.876145   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.920824   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.921815   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.922763   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.923688   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.924522   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.925374   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.926416   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.927396   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.928299   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.929227   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.930113   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.930964   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.932284   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.933326   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.934368   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.935413   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.936429   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.937435   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.943569   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.944618   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.945679   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.946980   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.948302   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.949610   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.950921   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.952234   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.953551   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.954790   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647730.956018   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.727816   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.728775   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.729652   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.730514   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.731364   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.732210   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.733049   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.733913   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.774661   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.775594   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.776475   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.777375   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.778366   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.779247   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.780102   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.780967   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.781884   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.782920   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.783849   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.784903   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.785983   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.831030   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.832040   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.833324   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.834678   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.835624   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.837991   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.838971   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.840091   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.841104   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.842121   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.843606   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.845989   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.847186   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.848348   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.849545   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.851435   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.852846   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.853891   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.855100   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.878721   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.879947   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.881219   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.882392   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.883628   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.885470   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.887177   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.888949   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.890630   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.891915   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.893749   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.895435   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.897648   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.899476   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.900935   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.902330   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.904791   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.906412   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.908647   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.910212   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.912939   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.928863   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.930172   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.931433   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.932636   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.933820   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.935058   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.936241   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.937448   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.938721   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.939994   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.941269   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.942625   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.946349   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.948012   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.949608   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.951482   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.954369   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.956284   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.958328   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.960494   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.984193   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.985431   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.986611   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.987819   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.989076   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.990288   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.991802   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.993463   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.995113   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.996496   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.998150   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647731.999801   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.001509   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.003165   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.004824   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.007040   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.009223   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.010820   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.012432   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.014081   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.015735   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.034531   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.035790   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.037079   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.038356   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.039637   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.040885   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.042228   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.043494   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.044803   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.046099   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.047391   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.048742   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.050084   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.051381   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.052707   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.054962   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.056411   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.058074   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.059533   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.061251   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.062698   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.064276   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.065872   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.067536   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.069480   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.071301   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.072949   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.096207   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.097547   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.098846   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.100477   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.101993   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.103582   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.105318   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.107042   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.108739   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.110471   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.112180   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.114416   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.116150   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.117887   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.119678   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.121682   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.125150   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.128700   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.130640   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.132608   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.134620   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.150865   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.152226   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.153590   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.154958   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.156341   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.157723   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.159062   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.160456   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.161958   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.163656   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.165390   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.167066   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.168754   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.170310   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.172038   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.173726   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.175556   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.177113   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.179063   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.181059   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.182619   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.184423   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.186239   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.188503   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.190158   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.205266   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.206398   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.207470   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.208786   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.210082   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.211396   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.212706   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.214042   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.215986   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.218088   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.219734   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.221388   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.227512   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.229768   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.232378   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.234947   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.241556   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.243928   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.247979   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.249260   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.263012   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.263855   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.264721   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.265602   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.266605   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.267558   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.268559   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.269578   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.270683   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.271748   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.272812   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.273891   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.275058   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.276256   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.277430   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.278465   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.279473   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.280482   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.281612   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.283020   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.284431   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.285992   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.287291   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.296874   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.298975   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.319508   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.320412   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.321422   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.322429   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.323595   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.324760   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.325942   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.327158   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.328375   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.329671   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.330926   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.332209   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.333523   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.334825   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.335866   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.336896   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.337897   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.339079   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.340599   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.342112   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.343616   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.344913   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.352900   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.372253   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.373248   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.374160   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.375069   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.375955   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.376851   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.377749   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.378674   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.379604   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.380836   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.381984   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.382994   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.384174   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.385715   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.387285   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.388724   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.390063   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.391414   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.393070   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.394583   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.396029   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.397815   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.399260   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.401774   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.403063   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.405375   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.407173   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.409504   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.412202   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.434886   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.436687   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.438441   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.440100   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.441913   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.443739   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.445476   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.447458   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.449201   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.451062   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.452903   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.454568   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.456507   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.458547   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.460517   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.462703   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.464669   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.466851   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.469433   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.471685   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.474384   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.476723   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.479047   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.481644   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.484489   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.507912   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.509511   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.511087   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.512662   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.514222   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.515766   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.517341   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.518988   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.520624   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.522224   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.523928   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.525630   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.527326   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.529016   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.530703   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.532339   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.533969   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.535660   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.537270   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.539176   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.541055   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.542958   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.544863   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.546832   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.549090   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.551378   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.553627   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.555744   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.560242   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.562699   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.565318   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.568276   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.570978   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.575852   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.580577   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.716394   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.718021   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.719791   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.721498   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.723091   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.724709   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.726341   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.727971   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.729745   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.731475   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.733326   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.735170   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.737030   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.738743   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.740491   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.742104   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.744126   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.746144   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.748576   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.751095   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.753649   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.756044   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.759005   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.761226   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.763626   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.765707   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.767785   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.792934   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.794477   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.795993   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.797529   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.799041   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.800568   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.802130   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.803718   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.805317   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.806876   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.808372   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.809936   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.811570   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.813203   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.814913   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.816649   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.818240   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.819818   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.821414   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.822916   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.824445   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.826040   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.827720   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.829569   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.831412   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.833080   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.834874   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.836675   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.838593   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.840693   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.842498   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.844763   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.846979   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.849509   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.852293   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.872535   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.874099   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.875675   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.877238   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.878797   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.880330   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.881931   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.883473   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.885188   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.886782   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.888485   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.890146   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.891872   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.893542   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.895396   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.897327   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.899214   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.901230   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.903668   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.906016   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.908922   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.911940   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.915188   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.918206   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.921608   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.945721   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.947542   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.949146   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.950787   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.952387   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.953991   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.955557   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.957132   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.958906   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.960505   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.962105   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.963730   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.965343   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.967047   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.968737   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.970454   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.972229   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.974021   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.975735   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.977546   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.979444   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.981263   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.983096   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.984799   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.986670   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.988401   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.990393   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.992913   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.994926   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647732.997450   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647733.000598   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647733.002907   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647733.005814   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647733.008481   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647733.013122   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647733.015926   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647733.036425   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647733.037471   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647733.038484   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647733.039484   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647733.040470   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647733.041476   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647733.042448   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647733.043428   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647733.044477   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647733.045610   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647733.046672   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647733.047844   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647733.048969   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647733.050125   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647733.051293   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647733.052573   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647733.055470   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647733.058392   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647733.061327   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647733.128313   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647733.129273   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647733.130234   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647733.131544   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647733.132838   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647733.134145   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647733.135474   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647733.136831   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647733.138779   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647733.140888   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647733.142582   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647733.144246   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647733.150388   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647733.152644   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647733.155255   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647733.157808   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647733.164372   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647733.166152   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647733.168602   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647733.169738   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647733.179791   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647733.180626   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647733.181515   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647733.182396   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647733.183359   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647733.184379   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647733.185439   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647733.186551   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647733.187640   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647733.188755   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647733.189825   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647733.191022   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647733.192242   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647733.193433   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647733.194460   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647733.195452   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647733.196464   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647733.197572   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647733.198981   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647733.200404   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647733.201891   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647733.203174   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1726647733.206469   11474 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0, Gen Loss: 103.05366516113281, Disc Loss: 0.8010265827178955\n",
      "Step 100, Gen Loss: 9.832321166992188, Disc Loss: 0.25081709027290344\n",
      "Step 200, Gen Loss: 7.747916221618652, Disc Loss: 0.8868225812911987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-18 08:24:25.899955: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Val Gen Loss: 7.891136646270752, Val Disc Loss: 1.0507009029388428\n",
      "Starting epoch 2/30\n",
      "Step 0, Gen Loss: 9.194904327392578, Disc Loss: 0.1828640103340149\n",
      "Step 100, Gen Loss: 7.390185832977295, Disc Loss: 0.5957521796226501\n",
      "Step 200, Gen Loss: 9.093101501464844, Disc Loss: 0.20429426431655884\n",
      "Epoch 2, Val Gen Loss: 6.556358814239502, Val Disc Loss: 0.8771077394485474\n",
      "Starting epoch 3/30\n",
      "Step 0, Gen Loss: 6.664956569671631, Disc Loss: 0.7822545170783997\n",
      "Step 100, Gen Loss: 7.294750213623047, Disc Loss: 0.45810467004776\n",
      "Step 200, Gen Loss: 6.376711368560791, Disc Loss: 0.43675655126571655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-18 08:28:59.316761: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Val Gen Loss: 12.244410514831543, Val Disc Loss: 1.0749834775924683\n",
      "Starting epoch 4/30\n",
      "Step 0, Gen Loss: 6.704522609710693, Disc Loss: 0.6828601360321045\n",
      "Step 100, Gen Loss: 7.818838119506836, Disc Loss: 0.3622378408908844\n",
      "Step 200, Gen Loss: 7.723816394805908, Disc Loss: 0.44298094511032104\n",
      "Epoch 4, Val Gen Loss: 5.392444133758545, Val Disc Loss: 0.7369373440742493\n",
      "Starting epoch 5/30\n",
      "Step 0, Gen Loss: 6.336214065551758, Disc Loss: 0.6568507552146912\n",
      "Step 100, Gen Loss: 7.495670318603516, Disc Loss: 0.7871432304382324\n",
      "Step 200, Gen Loss: 7.39288330078125, Disc Loss: 0.6163278222084045\n",
      "Epoch 5, Val Gen Loss: 34.73188400268555, Val Disc Loss: 1.3381327390670776\n",
      "Starting epoch 6/30\n",
      "Step 0, Gen Loss: 7.317423343658447, Disc Loss: 1.0670499801635742\n",
      "Step 100, Gen Loss: 6.269548416137695, Disc Loss: 0.6822963953018188\n",
      "Step 200, Gen Loss: 7.476166248321533, Disc Loss: 0.515040397644043\n",
      "Epoch 6, Val Gen Loss: 6.018011093139648, Val Disc Loss: 0.7590840458869934\n",
      "Starting epoch 7/30\n",
      "Step 0, Gen Loss: 7.100216865539551, Disc Loss: 0.7367198467254639\n",
      "Step 100, Gen Loss: 8.344477653503418, Disc Loss: 0.3545460104942322\n",
      "Step 200, Gen Loss: 8.550647735595703, Disc Loss: 0.3205634653568268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-18 08:38:22.595009: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Val Gen Loss: 7.984530448913574, Val Disc Loss: 1.1826726198196411\n",
      "Starting epoch 8/30\n",
      "Step 0, Gen Loss: 7.16767692565918, Disc Loss: 0.2071092128753662\n",
      "Step 100, Gen Loss: 6.388311386108398, Disc Loss: 0.6728230118751526\n",
      "Step 200, Gen Loss: 6.14961051940918, Disc Loss: 0.5637238621711731\n",
      "Epoch 8, Val Gen Loss: 12.085410118103027, Val Disc Loss: 3.4664459228515625\n",
      "Starting epoch 9/30\n",
      "Step 0, Gen Loss: 6.809215545654297, Disc Loss: 0.4490390419960022\n",
      "Step 100, Gen Loss: 7.044126510620117, Disc Loss: 0.4093555510044098\n",
      "Step 200, Gen Loss: 5.6979146003723145, Disc Loss: 0.6106045246124268\n",
      "Epoch 9, Val Gen Loss: 24.96553611755371, Val Disc Loss: 3.3490681648254395\n",
      "Starting epoch 10/30\n",
      "Step 0, Gen Loss: 6.338831901550293, Disc Loss: 0.5765310525894165\n",
      "Step 100, Gen Loss: 6.400763034820557, Disc Loss: 0.44048914313316345\n",
      "Step 200, Gen Loss: 5.640936374664307, Disc Loss: 0.9363867044448853\n",
      "Epoch 10, Val Gen Loss: 30.022701263427734, Val Disc Loss: 1.0768227577209473\n",
      "Starting epoch 11/30\n",
      "Step 0, Gen Loss: 8.462217330932617, Disc Loss: 0.35997629165649414\n",
      "Step 100, Gen Loss: 5.58476448059082, Disc Loss: 0.814693033695221\n",
      "Step 200, Gen Loss: 6.181628227233887, Disc Loss: 0.5919113755226135\n",
      "Epoch 11, Val Gen Loss: 6.174355983734131, Val Disc Loss: 0.8635447025299072\n",
      "Starting epoch 12/30\n",
      "Step 0, Gen Loss: 8.135250091552734, Disc Loss: 0.34845077991485596\n",
      "Step 100, Gen Loss: 5.54252815246582, Disc Loss: 0.5946202278137207\n",
      "Step 200, Gen Loss: 7.428016662597656, Disc Loss: 0.3859177529811859\n",
      "Epoch 12, Val Gen Loss: 14.439770698547363, Val Disc Loss: 4.26059103012085\n",
      "Starting epoch 13/30\n",
      "Step 0, Gen Loss: 5.794247150421143, Disc Loss: 0.6176210045814514\n",
      "Step 100, Gen Loss: 6.58925199508667, Disc Loss: 0.32808440923690796\n",
      "Step 200, Gen Loss: 5.77676248550415, Disc Loss: 0.5370767712593079\n",
      "Epoch 13, Val Gen Loss: 6.98048210144043, Val Disc Loss: 0.9703353643417358\n",
      "Starting epoch 14/30\n",
      "Step 0, Gen Loss: 7.037702560424805, Disc Loss: 0.6313107013702393\n",
      "Step 100, Gen Loss: 5.531274318695068, Disc Loss: 0.4476085305213928\n",
      "Step 200, Gen Loss: 5.655706882476807, Disc Loss: 0.47521108388900757\n",
      "Epoch 14, Val Gen Loss: 9.64864730834961, Val Disc Loss: 1.675469160079956\n",
      "Starting epoch 15/30\n",
      "Step 0, Gen Loss: 6.7490434646606445, Disc Loss: 0.5074204802513123\n",
      "Step 100, Gen Loss: 6.5186262130737305, Disc Loss: 0.41853025555610657\n",
      "Step 200, Gen Loss: 6.622635364532471, Disc Loss: 0.6411488056182861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-18 08:58:04.598195: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Val Gen Loss: 7.868004322052002, Val Disc Loss: 0.9007437229156494\n",
      "Starting epoch 16/30\n",
      "Step 0, Gen Loss: 6.1098856925964355, Disc Loss: 0.47009140253067017\n",
      "Step 100, Gen Loss: 6.437125205993652, Disc Loss: 0.42311662435531616\n",
      "Step 200, Gen Loss: 6.686859130859375, Disc Loss: 0.35899123549461365\n",
      "Epoch 16, Val Gen Loss: 6.505598068237305, Val Disc Loss: 0.6926729083061218\n",
      "Starting epoch 17/30\n",
      "Step 0, Gen Loss: 6.448575973510742, Disc Loss: 0.6243342161178589\n",
      "Step 100, Gen Loss: 5.767137050628662, Disc Loss: 0.5705248117446899\n",
      "Step 200, Gen Loss: 5.7242431640625, Disc Loss: 0.8377043008804321\n",
      "Epoch 17, Val Gen Loss: 13.94869613647461, Val Disc Loss: 3.3889312744140625\n",
      "Starting epoch 18/30\n",
      "Step 0, Gen Loss: 6.492584228515625, Disc Loss: 0.39949125051498413\n",
      "Step 100, Gen Loss: 6.330976486206055, Disc Loss: 0.6561007499694824\n",
      "Step 200, Gen Loss: 6.39008903503418, Disc Loss: 0.5847947001457214\n",
      "Epoch 18, Val Gen Loss: 6.630436420440674, Val Disc Loss: 0.8475738763809204\n",
      "Starting epoch 19/30\n",
      "Step 0, Gen Loss: 5.958003997802734, Disc Loss: 0.4134218692779541\n",
      "Step 100, Gen Loss: 6.376196384429932, Disc Loss: 0.6261348724365234\n",
      "Step 200, Gen Loss: 7.176477432250977, Disc Loss: 0.42997199296951294\n",
      "Epoch 19, Val Gen Loss: 9.405512809753418, Val Disc Loss: 2.1496965885162354\n",
      "Starting epoch 20/30\n",
      "Step 0, Gen Loss: 6.225008964538574, Disc Loss: 0.5129165649414062\n",
      "Step 100, Gen Loss: 5.6789727210998535, Disc Loss: 0.40718865394592285\n",
      "Step 200, Gen Loss: 6.455177307128906, Disc Loss: 0.6554960608482361\n",
      "Epoch 20, Val Gen Loss: 5.4696879386901855, Val Disc Loss: 0.7767989039421082\n",
      "Starting epoch 21/30\n",
      "Step 0, Gen Loss: 7.0262346267700195, Disc Loss: 0.4640607535839081\n",
      "Step 100, Gen Loss: 7.250133991241455, Disc Loss: 0.35946714878082275\n",
      "Step 200, Gen Loss: 7.321051597595215, Disc Loss: 0.3786246180534363\n",
      "Epoch 21, Val Gen Loss: 8.490397453308105, Val Disc Loss: 1.7115631103515625\n",
      "Starting epoch 22/30\n",
      "Step 0, Gen Loss: 7.445639610290527, Disc Loss: 0.46673712134361267\n",
      "Step 100, Gen Loss: 6.010579586029053, Disc Loss: 0.5848702192306519\n",
      "Step 200, Gen Loss: 6.672417163848877, Disc Loss: 0.7005488276481628\n",
      "Epoch 22, Val Gen Loss: 8.886151313781738, Val Disc Loss: 1.7429674863815308\n",
      "Starting epoch 23/30\n",
      "Step 0, Gen Loss: 6.417600631713867, Disc Loss: 0.39533376693725586\n",
      "Step 100, Gen Loss: 7.9180707931518555, Disc Loss: 0.39556536078453064\n",
      "Step 200, Gen Loss: 6.487382411956787, Disc Loss: 0.44109684228897095\n",
      "Epoch 23, Val Gen Loss: 8.929295539855957, Val Disc Loss: 1.7605022192001343\n",
      "Starting epoch 24/30\n",
      "Step 0, Gen Loss: 8.118037223815918, Disc Loss: 0.1728077530860901\n",
      "Step 100, Gen Loss: 5.882981777191162, Disc Loss: 0.6416573524475098\n",
      "Step 200, Gen Loss: 6.991196155548096, Disc Loss: 0.36774957180023193\n",
      "Epoch 24, Val Gen Loss: 14.94247055053711, Val Disc Loss: 4.936755180358887\n",
      "Starting epoch 25/30\n",
      "Step 0, Gen Loss: 7.447771072387695, Disc Loss: 0.31672394275665283\n",
      "Step 100, Gen Loss: 6.940065860748291, Disc Loss: 0.33914515376091003\n",
      "Step 200, Gen Loss: 7.963266372680664, Disc Loss: 0.2007380723953247\n",
      "Epoch 25, Val Gen Loss: 6.503626346588135, Val Disc Loss: 0.7586232423782349\n",
      "Starting epoch 26/30\n",
      "Step 0, Gen Loss: 7.508488655090332, Disc Loss: 0.35511529445648193\n",
      "Step 100, Gen Loss: 5.369614601135254, Disc Loss: 0.5483512878417969\n",
      "Step 200, Gen Loss: 6.338033199310303, Disc Loss: 0.5229337811470032\n",
      "Epoch 26, Val Gen Loss: 8.132542610168457, Val Disc Loss: 1.3757264614105225\n",
      "Starting epoch 27/30\n",
      "Step 0, Gen Loss: 5.719722747802734, Disc Loss: 0.5399881601333618\n",
      "Step 100, Gen Loss: 7.001491546630859, Disc Loss: 0.3775833249092102\n",
      "Step 200, Gen Loss: 6.5034098625183105, Disc Loss: 0.6128869652748108\n",
      "Epoch 27, Val Gen Loss: 6.598606586456299, Val Disc Loss: 0.8493077158927917\n",
      "Starting epoch 28/30\n",
      "Step 0, Gen Loss: 7.657218933105469, Disc Loss: 0.2731691896915436\n",
      "Step 100, Gen Loss: 6.920660018920898, Disc Loss: 0.4171081781387329\n",
      "Step 200, Gen Loss: 5.745297431945801, Disc Loss: 0.4210492968559265\n",
      "Epoch 28, Val Gen Loss: 14.680777549743652, Val Disc Loss: 4.768465042114258\n",
      "Starting epoch 29/30\n",
      "Step 0, Gen Loss: 5.323793411254883, Disc Loss: 0.5006073713302612\n",
      "Step 100, Gen Loss: 6.009300708770752, Disc Loss: 0.6405437588691711\n",
      "Step 200, Gen Loss: 6.726957321166992, Disc Loss: 0.3665294051170349\n",
      "Epoch 29, Val Gen Loss: 8.088028907775879, Val Disc Loss: 1.5212624073028564\n",
      "Starting epoch 30/30\n",
      "Step 0, Gen Loss: 6.357908248901367, Disc Loss: 0.6099175214767456\n",
      "Step 100, Gen Loss: 5.301379203796387, Disc Loss: 0.6299293041229248\n",
      "Step 200, Gen Loss: 6.637729644775391, Disc Loss: 0.45902353525161743\n",
      "Epoch 30, Val Gen Loss: 6.291413307189941, Val Disc Loss: 0.8346407413482666\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "class GANMonitor:\n",
    "    def __init__(self, log_dir=\"logs/\"):\n",
    "        current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        self.train_log_dir = os.path.join(log_dir, current_time, 'train')\n",
    "        self.val_log_dir = os.path.join(log_dir, current_time, 'validation')\n",
    "        self.train_summary_writer = tf.summary.create_file_writer(self.train_log_dir)\n",
    "        self.val_summary_writer = tf.summary.create_file_writer(self.val_log_dir)\n",
    "        \n",
    "    def log_losses(self, gen_loss, disc_loss, step, is_training=True):\n",
    "        writer = self.train_summary_writer if is_training else self.val_summary_writer\n",
    "        with writer.as_default():\n",
    "            tf.summary.scalar('generator_loss', gen_loss, step=step)\n",
    "            tf.summary.scalar('discriminator_loss', disc_loss, step=step)\n",
    "\n",
    "def wasserstein_loss(y_true, y_pred):\n",
    "    return tf.reduce_mean(y_true * y_pred)\n",
    "\n",
    "def gradient_penalty(discriminator, real_samples, fake_samples, input_images):\n",
    "    batch_size = tf.shape(real_samples)[0]\n",
    "    alpha = tf.random.uniform([batch_size, 1, 1, 1], 0.0, 1.0)\n",
    "    interpolated = real_samples + alpha * (fake_samples - real_samples)\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(interpolated)\n",
    "        validity = discriminator([input_images, interpolated], training=True)\n",
    "    \n",
    "    gradients = tape.gradient(validity, interpolated)\n",
    "    gradients_sqr = tf.square(gradients)\n",
    "    gradients_sqr_sum = tf.reduce_sum(gradients_sqr, axis=[1, 2, 3])\n",
    "    gradient_l2_norm = tf.sqrt(gradients_sqr_sum)\n",
    "    gradient_penalty = tf.square(gradient_l2_norm - 1)\n",
    "    return tf.reduce_mean(gradient_penalty)\n",
    "\n",
    "def train_cgan(generator, discriminator, train_dataset, val_dataset, epochs=30):\n",
    "    binary_cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "    monitor = GANMonitor()\n",
    "    \n",
    "    # Learning rate schedulers\n",
    "    initial_lr = 2e-4\n",
    "    gen_lr_scheduler = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_lr, decay_steps=1000, decay_rate=0.96, staircase=True)\n",
    "    disc_lr_scheduler = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_lr, decay_steps=1000, decay_rate=0.96, staircase=True)\n",
    "    \n",
    "    generator.optimizer = tf.keras.optimizers.Adam(gen_lr_scheduler, beta_1=0.5)\n",
    "    discriminator.optimizer = tf.keras.optimizers.Adam(disc_lr_scheduler, beta_1=0.5)\n",
    "    \n",
    "    def generator_loss(disc_generated_output, gen_output, target):\n",
    "        # Adversarial loss\n",
    "        adv_loss = wasserstein_loss(tf.ones_like(disc_generated_output), disc_generated_output)\n",
    "        \n",
    "        # L1 loss\n",
    "        l1_loss = tf.reduce_mean(tf.abs(target - gen_output))\n",
    "        \n",
    "        # Perceptual loss (using pre-trained VGG features)\n",
    "        # Note: You'll need to implement get_perceptual_loss based on your needs\n",
    "        # perceptual_loss = get_perceptual_loss(target, gen_output)\n",
    "        \n",
    "        # Total loss\n",
    "        total_gen_loss = adv_loss + (lambda_l1 * l1_loss)  # + (lambda_p * perceptual_loss)\n",
    "        return total_gen_loss, {'adv_loss': adv_loss, 'l1_loss': l1_loss}\n",
    "    \n",
    "    def discriminator_loss(disc_real_output, disc_generated_output):\n",
    "        real_loss = wasserstein_loss(tf.ones_like(disc_real_output), disc_real_output)\n",
    "        fake_loss = wasserstein_loss(-tf.ones_like(disc_generated_output), disc_generated_output)\n",
    "        total_disc_loss = (real_loss + fake_loss) * 0.5\n",
    "        return total_disc_loss\n",
    "    \n",
    "    # Training metrics\n",
    "    train_gen_loss = tf.keras.metrics.Mean('train_generator_loss', dtype=tf.float32)\n",
    "    train_disc_loss = tf.keras.metrics.Mean('train_discriminator_loss', dtype=tf.float32)\n",
    "    \n",
    "    steps_per_epoch = len(train_dataset)\n",
    "    total_steps = steps_per_epoch * epochs\n",
    "    global_step = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f'\\nEpoch {epoch+1}/{epochs}')\n",
    "        \n",
    "        # Training loop\n",
    "        pbar = tqdm(train_dataset, total=steps_per_epoch, desc=f'Training')\n",
    "        for step, (monlam_images, derge_images) in enumerate(pbar):\n",
    "            with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "                # Generator forward pass\n",
    "                generated_images = generator(monlam_images, training=True)\n",
    "                \n",
    "                # Discriminator forward passes\n",
    "                real_output = discriminator([monlam_images, derge_images], training=True)\n",
    "                fake_output = discriminator([monlam_images, generated_images], training=True)\n",
    "                \n",
    "                # Calculate losses\n",
    "                gen_loss, gen_loss_dict = generator_loss(fake_output, generated_images, derge_images)\n",
    "                disc_loss = discriminator_loss(real_output, fake_output)\n",
    "                \n",
    "                # Add gradient penalty\n",
    "                gp = gradient_penalty(discriminator, derge_images, generated_images, monlam_images)\n",
    "                disc_loss += 10.0 * gp\n",
    "            \n",
    "            # Compute and apply gradients\n",
    "            gen_gradients = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "            disc_gradients = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "            \n",
    "            # Clip gradients\n",
    "            gen_gradients = [tf.clip_by_norm(g, 1.0) for g in gen_gradients]\n",
    "            disc_gradients = [tf.clip_by_norm(g, 1.0) for g in disc_gradients]\n",
    "            \n",
    "            # Update weights\n",
    "            generator.optimizer.apply_gradients(zip(gen_gradients, generator.trainable_variables))\n",
    "            discriminator.optimizer.apply_gradients(zip(disc_gradients, discriminator.trainable_variables))\n",
    "            \n",
    "            # Update metrics\n",
    "            train_gen_loss.update_state(gen_loss)\n",
    "            train_disc_loss.update_state(disc_loss)\n",
    "            \n",
    "            # Update progress bar\n",
    "            pbar.set_postfix({\n",
    "                'gen_loss': f'{gen_loss.numpy():.4f}',\n",
    "                'disc_loss': f'{disc_loss.numpy():.4f}',\n",
    "                'l1_loss': f'{gen_loss_dict[\"l1_loss\"].numpy():.4f}'\n",
    "            })\n",
    "            \n",
    "            # Log to TensorBoard\n",
    "            monitor.log_losses(gen_loss, disc_loss, global_step)\n",
    "            global_step += 1\n",
    "        \n",
    "        # Validation loop\n",
    "        val_gen_losses = []\n",
    "        val_disc_losses = []\n",
    "        print(\"\\nValidating...\")\n",
    "        for monlam_images, derge_images in tqdm(val_dataset, desc='Validation'):\n",
    "            # Generate images\n",
    "            generated_images = generator(monlam_images, training=False)\n",
    "            \n",
    "            # Calculate validation losses\n",
    "            real_output = discriminator([monlam_images, derge_images], training=False)\n",
    "            fake_output = discriminator([monlam_images, generated_images], training=False)\n",
    "            \n",
    "            gen_loss, _ = generator_loss(fake_output, generated_images, derge_images)\n",
    "            disc_loss = discriminator_loss(real_output, fake_output)\n",
    "            \n",
    "            val_gen_losses.append(gen_loss.numpy())\n",
    "            val_disc_losses.append(disc_loss.numpy())\n",
    "        \n",
    "        # Log validation metrics\n",
    "        avg_val_gen_loss = np.mean(val_gen_losses)\n",
    "        avg_val_disc_loss = np.mean(val_disc_losses)\n",
    "        monitor.log_losses(avg_val_gen_loss, avg_val_disc_loss, epoch, is_training=False)\n",
    "        \n",
    "        print(f'Validation Metrics:')\n",
    "        print(f'Generator Loss: {avg_val_gen_loss:.4f}')\n",
    "        print(f'Discriminator Loss: {avg_val_disc_loss:.4f}')\n",
    "        \n",
    "        # Save model checkpoints\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            generator.save_weights(f'generator_epoch_{epoch+1}.h5')\n",
    "            discriminator.save_weights(f'discriminator_epoch_{epoch+1}.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97600472-266a-46e1-8501-cec0db075294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def generate_and_display_images(generator, test_dataset, num_images=5):\n",
    "    for conditonal_images, _ in test_dataset.take(1): \n",
    "        generated_images = generator(conditonal_images, training=False)\n",
    "        \n",
    "        plt.figure(figsize=(15, 5))\n",
    "        for i in range(num_images):\n",
    "            plt.subplot(1, num_images, i + 1)\n",
    "            plt.imshow((generated_images[i] + 1) / 2.0, cmap='gray') \n",
    "            plt.axis('off')\n",
    "        plt.show()\n",
    "        break  \n",
    "\n",
    "generate_and_display_images(generator, test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666e38ae-c7fd-4c23-8400-0d7867281a71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
